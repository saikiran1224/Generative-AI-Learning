{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHNf7J680XF-"
      },
      "source": [
        "# Word Embedding Techniques using Embedding Layer in Keras\n",
        "\n",
        "Libraries Used Tensorflow> 2.0  and keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pslw1Ya90XGC",
        "outputId": "a2aedfb9-ef16-46d8-d3c8-0676c3cfb44b"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu # No need to install this cell explicitly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcUi0JwY89mt"
      },
      "source": [
        "## Importing Tensorflow Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ5hceiMAX7n",
        "outputId": "18002457-a916-40e9-ec92-ce1cef5c0f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__) # checking the version of tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxOfJQdR87J9"
      },
      "source": [
        "## Importing OHE from tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k4nKifUl0XGC"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evadjZgR9LuU"
      },
      "source": [
        "## Declaring Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu9PuYeu0XGD"
      },
      "outputs": [],
      "source": [
        "### sentences\n",
        "sent=['the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5d1D3_20XGD",
        "outputId": "a8e026f0-4077-4789-b903-fc92a428103c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJLZZenR9QVx"
      },
      "source": [
        "## Explicitly specifying Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjnXIn3B0XGE"
      },
      "outputs": [],
      "source": [
        "### Vocabulary size - More the size more the processing\n",
        "\n",
        "# Its a Hyperparameter. More the vocabulary size, we will get good feature representation.\n",
        "\n",
        "voc_size = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQOdeKk0XGE"
      },
      "source": [
        "## One Hot Representation\n",
        "\n",
        "Converting the given sentences into One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojfZpAW0XGE",
        "outputId": "3b5d620d-32bc-40af-ac60-18f485f5ef30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[277, 303, 96, 188], [277, 303, 96, 300], [277, 377, 96, 136], [279, 465, 443, 287, 151], [279, 465, 443, 287, 457], [436, 277, 200, 96, 66], [31, 194, 161, 287]]\n"
          ]
        }
      ],
      "source": [
        "onehot_repr = [one_hot(sentence,voc_size)for sentence in sent]\n",
        "\n",
        "print(onehot_repr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6bSh4cS9r52"
      },
      "source": [
        "### Understanding above output\n",
        "\n",
        "As we specified the vocabulary size explicitly as 10,000. An array of 10,000 indexes gets generated and once we pass the each sentence to the `one_hot(sentence, voc_size)` iterating over the sentences list, then it will return the output of the indexes where that particular word is present in the given vocabulary.\n",
        "\n",
        "For example: [277, 8459, 2709, 7322]\n",
        "\n",
        "Here 1220 means for the word 'the' index is 1220 in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYG267x40XGF"
      },
      "source": [
        "## Word Embedding Represntation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K_QBQfsyzEP"
      },
      "source": [
        "## Importing embedding layer, padding and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpqPm0tb0XGF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rov3GTM00XGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9RywpHGA9Dc"
      },
      "source": [
        "## Padding\n",
        "\n",
        "We need the size of all the sentences to be equal while training the ANN.\n",
        "\n",
        "Hence, we will specify the maximum Sentence length or more here we are keeping as 8, and then we will use help of **Padding** where it will add zeroes at the front or at the end based on \"pre\" or \"post\" padding specified.\n",
        "\n",
        "THIS PROCESS REMAINS COMMON FOR ALL THE NLP APPLICATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOjCUMkozCU-"
      },
      "source": [
        "## Specifying the sentence length\n",
        "\n",
        "Based on the length specified here, all the sentences gets convered into the same size. If we dont have any word present in the required length, then automatically zeroes (0) gets added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K7vT1t-zaAy"
      },
      "outputs": [],
      "source": [
        "sent_length = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fQLPw6p0XGG",
        "outputId": "a64f543b-c930-484d-f6b0-10abfde52ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0 277 303  96 188]\n",
            " [  0   0   0   0 277 303  96 300]\n",
            " [  0   0   0   0 277 377  96 136]\n",
            " [  0   0   0 279 465 443 287 151]\n",
            " [  0   0   0 279 465 443 287 457]\n",
            " [  0   0   0 436 277 200  96  66]\n",
            " [  0   0   0   0  31 194 161 287]]\n"
          ]
        }
      ],
      "source": [
        "## pre padding\n",
        "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofxLCd8VCET5"
      },
      "source": [
        "## Declaring Feature Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjQqBYac0XGG"
      },
      "outputs": [],
      "source": [
        "## 10 feature dimesnions\n",
        "\n",
        "dim = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AuvywdKzuEX"
      },
      "source": [
        "## Training the ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozC-TXrt0XGG"
      },
      "outputs": [],
      "source": [
        "model = Sequential() # creating an object of the Sequential class\n",
        "\n",
        "# Embedding layer works similar to Word2Vec\n",
        "model.add(Embedding(voc_size, # Vocabulary size\n",
        "                    10, # Dimension lenghth - Features required for each vector (means every vector represented in 10 dimensions)\n",
        "                    input_length=sent_length)) # Sentences length\n",
        "\n",
        "model.compile('adam','mse') # Compiling with Adam optimizer and MSE loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "tMNvq-Ji0XGH",
        "outputId": "5b399e3a-e9f3-4d32-e140-8146f532f2f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXE-3bRlC2w2"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5RjsJNCC5r-",
        "outputId": "06f5a04c-12c2-472c-bbe1-9da4799d8c10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 1220, 8459, 2709, 7322], dtype=int32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedded_docs[0] # After padding first sentence - the glass of milk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOWlD65QC_u_",
        "outputId": "3f07a4df-06e8-4d93-bb3c-7651c3759e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(embedded_docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzKP69gx0XGH",
        "outputId": "cdfbaefd-0ff9-4d3c-d2ff-37c66c150aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(embedded_docs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njTC9TFnQjH0"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcpCe2_sQrOz"
      },
      "source": [
        "## Step 1: Declaring Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8OMu3iAz0XGH"
      },
      "outputs": [],
      "source": [
        "#Assignment\n",
        "\n",
        "sentences = [\"The world is a better place\",\n",
        "      \"Marvel series is my favourite movie\",\n",
        "      \"I like DC movies\",\n",
        "      \"the cat is eating the food\",\n",
        "      \"Tom and Jerry is my favourite movie\",\n",
        "      \"Python is my favourite programming language\"\n",
        "      ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jai2K1hQvz9"
      },
      "source": [
        "## Step 2: Importing tensorflow library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1adxu5fQlv1",
        "outputId": "ad656116-8f3d-4a59-aa77-d1b969cb711a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9KX3EcoRiEC"
      },
      "source": [
        "## Step 3: Declare Vocabulary Size\n",
        "\n",
        "We need to specify the Vocabulary size now as it will be used by the one hot encoding to assign the index during the conversion.\n",
        "\n",
        "Remember the more the Vocabulary size, the good will be the feature representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GbJWIt-2R1BW"
      },
      "outputs": [],
      "source": [
        "voc_size = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0eDRC52Q9tY"
      },
      "source": [
        "## Step 3: Convert the sentences into OHE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHeLMkKXRBPB"
      },
      "source": [
        "### Importing library from TF Keras to perform OHE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z7RInFChQ52Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ne6mrhQSjTC"
      },
      "source": [
        "### Representing each sentence in form of OHE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lU89XJSbRLWc"
      },
      "outputs": [],
      "source": [
        "onehot_embedded_docs = [ one_hot(sentence, voc_size) for sentence in sentences] # converting the sentences into one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeSJuEryRcaZ",
        "outputId": "cb7bc731-7901-499e-829a-686d490cdf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[483, 422, 232, 32, 33, 352], [109, 157, 232, 99, 313, 476], [134, 223, 201, 336], [483, 361, 232, 230, 483, 246], [230, 462, 476, 232, 99, 313, 476], [123, 232, 99, 313, 484, 150]]\n"
          ]
        }
      ],
      "source": [
        "print(onehot_embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8iKAvIfSQwn"
      },
      "source": [
        "In the above output, since we specified the vocabulary size as 500 all the indexes lies between the value of 0 to 500.\n",
        "\n",
        "483 is the index for the word \"The\", 422 is the index for the word \"world\", so on and so forth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynia05DTStei"
      },
      "source": [
        "## Step 4: Applying padding to make sentences length equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5meSEowLTQVb"
      },
      "source": [
        "### Importing library to perform padding from keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qZWHPrAESOsZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlSFCn0GTfg9"
      },
      "source": [
        "The maximum sentence length in the given corpus is 6. Lets us consider the sentence length as 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8_kD9P-OTYkI"
      },
      "outputs": [],
      "source": [
        "sent_length = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4KFNiI6TrOd"
      },
      "source": [
        "### Performing pre-padding operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WEztcoWJTpFi"
      },
      "outputs": [],
      "source": [
        "onehot_embedded_docs_padded = pad_sequences(onehot_embedded_docs, # passing the documents which are one hot encoded\n",
        "                                            padding='pre', # choosing prepadding\n",
        "                                            maxlen=sent_length) # specifying the maximum sentence lenghth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6PeSstAUAuh",
        "outputId": "829cce1c-56cb-4f0d-be99-d034731c8496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0, 483, 422, 232,  32,  33, 352],\n",
              "       [  0,   0,   0,   0, 109, 157, 232,  99, 313, 476],\n",
              "       [  0,   0,   0,   0,   0,   0, 134, 223, 201, 336],\n",
              "       [  0,   0,   0,   0, 483, 361, 232, 230, 483, 246],\n",
              "       [  0,   0,   0, 230, 462, 476, 232,  99, 313, 476],\n",
              "       [  0,   0,   0,   0, 123, 232,  99, 313, 484, 150]], dtype=int32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_embedded_docs_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKo5wFhgUDZe"
      },
      "source": [
        "As we can observe the output, all the sentences are converted to the fixed length of 10. Now, at this point we are good to go and train our data with our ANN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1W4PczuUNl1"
      },
      "source": [
        "## Step 5: Finding the Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZRJMXlbUVBr"
      },
      "source": [
        "### Importing sequential and embedding from keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QrvB_jBfUB2n"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential # Sequential model\n",
        "from tensorflow.keras.layers import Embedding # Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEl_W-aWUi9W"
      },
      "source": [
        "### Creating object of Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ESD2I7VBUiBI"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2_8NRUJUpFt"
      },
      "source": [
        "### Adding the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUGcf4tUoCn",
        "outputId": "b978b1a7-24da-4c54-b26c-461418d17e05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model.add(Embedding(input_dim=voc_size, # Inserting the vocabulary size\n",
        "                    output_dim=5, # output dimension specified 5 (Post padding each sentence is represented in 10 indexes, here each index value gets represented in form of 5 unique dimensions)\n",
        "                    input_length=sent_length)) # specifying our sentence length as 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzX4C2rkVAvF"
      },
      "source": [
        "### Viewing the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "iu4DExeJU_3z",
        "outputId": "ab355f6a-d4c5-45aa-e3ed-b44ee21cd2b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQGkg-qEVs9F"
      },
      "source": [
        "## Step 6: Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_pdxXOzVxD3"
      },
      "source": [
        "Lets first display our first sentence in our corpus after padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVCUHM7CVnus",
        "outputId": "fdc3c624-bebb-4f8c-f593-aeebf037525a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0, 483, 422, 232,  32,  33, 352], dtype=int32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_embedded_docs_padded[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44rfIHBuWERF",
        "outputId": "eb6318dc-7b5d-4046-e98e-d147b428fda8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_embedded_docs_padded[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEHBMybhV420",
        "outputId": "106709fd-2435-4ece-9d99-c63adc7526e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 3.0929152e-02,  6.5941699e-03, -1.5458070e-02,  4.1523203e-03,\n",
              "        -4.8915006e-02],\n",
              "       [ 3.0929152e-02,  6.5941699e-03, -1.5458070e-02,  4.1523203e-03,\n",
              "        -4.8915006e-02],\n",
              "       [ 3.0929152e-02,  6.5941699e-03, -1.5458070e-02,  4.1523203e-03,\n",
              "        -4.8915006e-02],\n",
              "       [ 3.0929152e-02,  6.5941699e-03, -1.5458070e-02,  4.1523203e-03,\n",
              "        -4.8915006e-02],\n",
              "       [ 2.0910725e-03, -4.4374395e-02,  4.9491551e-02,  1.6825352e-02,\n",
              "         1.8227100e-04],\n",
              "       [ 9.2148185e-03,  1.1051595e-02,  3.4328811e-03,  1.8353675e-02,\n",
              "         1.4357869e-02],\n",
              "       [-1.7058171e-02, -9.2722066e-03, -1.9316785e-03, -3.0861974e-02,\n",
              "         3.6418941e-02],\n",
              "       [ 7.5140819e-03, -3.3537269e-02,  5.3764097e-03, -3.8585819e-02,\n",
              "         8.7975748e-03],\n",
              "       [-2.8642654e-02, -4.1455485e-02, -2.8335845e-02, -1.5461337e-02,\n",
              "        -3.0452037e-02],\n",
              "       [-1.1373311e-05,  1.5189733e-02,  1.4620211e-02,  4.4613812e-02,\n",
              "         1.5127230e-02]], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(onehot_embedded_docs_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8JivRpiV8lA",
        "outputId": "f3a7eefb-e054-49c7-f963-85f8285c6716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(onehot_embedded_docs_padded[0]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cYOsUflWGc6"
      },
      "source": [
        "### Understanding output\n",
        "\n",
        "If we closely notice the dimensions of our original document which is (10,1) - 10 rows and 1 column. It means the first sentence \"The world is a better place\" is now represented in (10,1) after one hot encoding and after applyinhg padding.\n",
        "\n",
        "Now, once the same is passed to the embedding layer, each word/index is converted into 5 columns of data representing unique vector. Hence the updated dimension is 10 * 5."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
