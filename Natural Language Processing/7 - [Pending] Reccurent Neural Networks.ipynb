{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of today, the most efficient word to vector conversion technique is \"Word2Vec and AvgWord2Vec\" which will create Word embeddings. Deep Learning and embedding layer is used in the Word2Vec technique making it more efficient than the other available techniques or models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Applications of NLP\n",
    "\n",
    "Lets have a glance of the various use cases of Natual Language processing which is currently used in the tech industry. They are the following: \n",
    "\n",
    "- Chatbot: Question and Answer (Sequence of words is highly IMPORTANT) \n",
    "\n",
    "- Language Translation: One language -> Another language (Sequence of words is highly IMPORTANT) \n",
    "\n",
    "- Text Generation: Sentence generation and Auto-completeness (Completion of sentences in Gmail, LinkedIn, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above mentioned applications of NLP, we cannot use Machine Learning as it will not provide the required accuracy. Hence, we need to choose the Deep Learning to provide good accuracy. In the RNN, once the corpus is tokenized into sentences, all the words are converted into word embeddings into Word2Vec algorithm. \n",
    "\n",
    "Also, RNN can also used for Time series data along with the general text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://miro.medium.com/v2/resize:fit:1400/1*xs2EgGPGlpWrSW4zUANYXA.png)\n",
    "\n",
    "\n",
    "<a href=\"https://www.google.com/url?sa=i&url=https%3A%2F%2Fvijaygadre.medium.com%2Frecurrent-neural-networks-a-beginners-guide-16333bd2eeb1&psig=AOvVaw0AuvHBn53v6bU6H6Asu2jy&ust=1738729751605000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCPiDrZ6XqYsDFQAAAAAdAAAAABAY\">Image Credits</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the architecture of RNN, considering a single neuron architecture we have only one Input and one Output and the output is again carry forwarded back to the hidden neuron. \n",
    "\n",
    "### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above mentioned diagram, in the extreme left is the Simple single neuron architecture of RNN. As mentioned before, A is our hidden neuron it can also be group of multiple hidden neurons. \n",
    "\n",
    "$\\ X_t$ is the Input provided and $\\ h_t$ is the Output.\n",
    "\n",
    "If we expand the architecture of this architecture then it can be represented as shown to the right. Once the output is produced it gets attached to the next hidden neuron, and so on and so forth. \n",
    "\n",
    "That being said, we have total four types of RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of RNN\n",
    "\n",
    "There are total four types of RNN:\n",
    "\n",
    "1. One to One RNN\n",
    "\n",
    "2. One to Many RNN\n",
    "\n",
    "3. Many to One RNN\n",
    "4. Many to Many RNN\n",
    "\n",
    "Below is the picture showing all the four types of RNNs at once: \n",
    "\n",
    "![Image](https://miro.medium.com/v2/resize:fit:1400/1*sBjt1ETilcG7cmGY9heoag.png)\n",
    "\n",
    "<a href=\"https://www.google.com/url?sa=i&url=https%3A%2F%2Fpub.towardsai.net%2Funlocking-the-power-of-recurrent-neural-networks-a-beginners-guide-46956618a959&psig=AOvVaw0fb3zpeHMgB8oeVKGmWVtU&ust=1738903656851000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCPCl1YmfrosDFQAAAAAdAAAAABAJ\">Image Credits</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. One to One RNN\n",
    " \n",
    "As we can see in the above picture, in One to One RNN, there will be one single hidden neuron and on providing input it provides an output. \n",
    "\n",
    "**Applications:** Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. One to Many RNN\n",
    "\n",
    "In One to Many RNN, there will be one single hidden neuron taking the input, but the output gets passed to the next node and likewise at every instance the output gets produced.\n",
    "\n",
    "**Applications:** Music Generation, Text Generator, Google Search (one phrase - multiple recommendations) and Movie Recommendation (based on one movie it recommends many things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Many to One RNN\n",
    "\n",
    "Multiple inputs are provided but only one Output is provided. Here, the RNN clearly gets understands the context and a final output will be provided. \n",
    "\n",
    "**Applications:** Predicting next word, Sentiment Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Many to Many RNN\n",
    "\n",
    "Multiple inputs are given and multiple outputs are provided by the RNN. \n",
    "\n",
    "**Applications:** Language Translation,Chatbot and Question Answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawback of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unable to identify the overall context completely. For example two sentences: Krish loves to play. He also loves to study. RNN will treat both sentences seperately and it will not be able to identify context of 'He'. \n",
    "\n",
    "- Vanishing gradient problem and Dead Neurons. When uses Sigmoid activation function and the RNN is deep then weights will mostly not be updated and negligible."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
