{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHNf7J680XF-"
      },
      "source": [
        "### Word Embedding Techniques using Embedding Layer in Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEsK0_yl0XGB"
      },
      "outputs": [],
      "source": [
        "### Libraries USed Tensorflow> 2.0  and keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pslw1Ya90XGC",
        "outputId": "a2aedfb9-ef16-46d8-d3c8-0676c3cfb44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu # No need to install this cell explicitly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Tensorflow Library"
      ],
      "metadata": {
        "id": "XcUi0JwY89mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__) # checking the version of tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ5hceiMAX7n",
        "outputId": "7f60d905-6d49-447e-b78d-dd838c21b5d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing OHE from tf"
      ],
      "metadata": {
        "id": "uxOfJQdR87J9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k4nKifUl0XGC"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring Sentences"
      ],
      "metadata": {
        "id": "evadjZgR9LuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fu9PuYeu0XGD"
      },
      "outputs": [],
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5d1D3_20XGD",
        "outputId": "8c621010-40b5-42c1-b716-3a779e1be089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicitly specifying Vocabulary"
      ],
      "metadata": {
        "id": "AJLZZenR9QVx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tjnXIn3B0XGE"
      },
      "outputs": [],
      "source": [
        "### Vocabulary size - More the size more the processing\n",
        "\n",
        "# Its a Hyperparameter. More the vocabulary size, we will get good feature representation.\n",
        "\n",
        "voc_size=500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQOdeKk0XGE"
      },
      "source": [
        "## One Hot Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojfZpAW0XGE",
        "outputId": "0d1c6b77-b988-497d-f564-b26bc0fc6340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1220, 8459, 2709, 7322], [1220, 8459, 2709, 4829], [1220, 1617, 2709, 3836], [5, 7174, 8535, 6742, 3524], [5, 7174, 8535, 6742, 3097], [5898, 1220, 5065, 2709, 8257], [3628, 5702, 7515, 6742]]\n"
          ]
        }
      ],
      "source": [
        "onehot_repr = [one_hot(sentence,voc_size)for sentence in sent]\n",
        "\n",
        "print(onehot_repr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding above output\n",
        "\n",
        "As we specified the vocabulary size explicitly as 10,000. An array of 10,000 indexes gets generated and once we pass the each sentence to the `one_hot(sentence, voc_size)` iterating over the sentences list, then it will return the output of the indexes where that particular word is present in the given vocabulary.\n",
        "\n",
        "For example: [1220, 8459, 2709, 7322]\n",
        "\n",
        "Here 1220 means for the word 'the' index is 1220 in the vocabulary."
      ],
      "metadata": {
        "id": "G6bSh4cS9r52"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYG267x40XGF"
      },
      "source": [
        "## Word Embedding Represntation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wpqPm0tb0XGF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Rov3GTM00XGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding\n",
        "\n",
        "We need the size of all the sentences to be equal while training the ANN.\n",
        "\n",
        "Hence, we will specify the maximum Sentence length or more here we are keeping as 8, and then we will use help of **Padding** where it will add zeroes at the front or at the end based on \"pre\" or \"post\" padding specified."
      ],
      "metadata": {
        "id": "z9RywpHGA9Dc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fQLPw6p0XGG",
        "outputId": "71526942-2d0b-4dfb-a000-dd6b26fb4f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 1220 8459 2709 7322]\n",
            " [   0    0    0    0 1220 8459 2709 4829]\n",
            " [   0    0    0    0 1220 1617 2709 3836]\n",
            " [   0    0    0    5 7174 8535 6742 3524]\n",
            " [   0    0    0    5 7174 8535 6742 3097]\n",
            " [   0    0    0 5898 1220 5065 2709 8257]\n",
            " [   0    0    0    0 3628 5702 7515 6742]]\n"
          ]
        }
      ],
      "source": [
        "## pre padding\n",
        "sent_length=8\n",
        "\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring Feature Dimensions"
      ],
      "metadata": {
        "id": "ofxLCd8VCET5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yjQqBYac0XGG"
      },
      "outputs": [],
      "source": [
        "## 10 feature dimesnions\n",
        "\n",
        "dim=10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ozC-TXrt0XGG"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "\n",
        "# Embedding layer works similar to Word2Vec\n",
        "model.add(Embedding(voc_size, # Vocabulary size\n",
        "                    10, # Dimension lenghth - Features required for each vector (means every vector represented in 10 dimensions)\n",
        "                    input_length=sent_length)) # Sentences lenght\n",
        "\n",
        "model.compile('adam','mse') # Compiling with Adam optimizer and MSE loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "tMNvq-Ji0XGH",
        "outputId": "08e092b0-2d07-49d3-edb3-1fb097133c11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting"
      ],
      "metadata": {
        "id": "lXE-3bRlC2w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOWlD65QC_u_",
        "outputId": "3f07a4df-06e8-4d93-bb3c-7651c3759e61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0] # After padding first sentence - the glass of milk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5RjsJNCC5r-",
        "outputId": "06f5a04c-12c2-472c-bbe1-9da4799d8c10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 1220, 8459, 2709, 7322], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzKP69gx0XGH",
        "outputId": "cdfbaefd-0ff9-4d3c-d2ff-37c66c150aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [-0.01417743,  0.02342245, -0.00028545, -0.04773829,  0.0269583 ,\n",
              "        -0.03326305,  0.04963494,  0.0115789 , -0.03794973, -0.01383566],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ],\n",
              "       [ 0.03374443, -0.04046713,  0.01686255,  0.03337267,  0.03554653,\n",
              "         0.01253268,  0.01704322, -0.02261758, -0.0099019 , -0.0373638 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.predict(embedded_docs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OMu3iAz0XGH"
      },
      "outputs": [],
      "source": [
        "#Assignment\n",
        "\n",
        "sent=[\"The world is a better place\",\n",
        "      \"Marvel series is my favourite movie\",\n",
        "      \"I like DC movies\",\n",
        "      \"the cat is eating the food\",\n",
        "      \"Tom and Jerry is my favourite movie\",\n",
        "      \"Python is my favourite programming language\"\n",
        "      ]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}