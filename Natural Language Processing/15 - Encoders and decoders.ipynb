{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to learn about Encoders and Decoders, let us understand about Sequence to Sequence with RNN. It is defined as the model takes sequence of information and gives output as Sequence of information. \n",
    "\n",
    "Some of the best examples include: \n",
    "- Language Translation (One language -> Another language)\n",
    "\n",
    "- Image Captioning (Google Image search)\n",
    "- Auto-reply suggesstions in LinkedIn, Microsoft Teams, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoders and Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might get a question like an LSTM can itself process the sequence to sequence information, but then what will be the use of Encoders and Decoders. \n",
    "\n",
    "Usually the traditional architecture of LSTM is capable of processing the sentences seuquentially and remembering the context and accordingly it will help in performing basic tasks like Sentiment analysis and Time series prediction but not suitable for large tasks like Language translation, etc. Hence, we use the help of Encoders and Decoders to perform such tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main components in this architecture are:\n",
    "\n",
    "1. Encoders\n",
    "2. Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](https://miro.medium.com/v2/0*XCF22nmg4Qn1i3iC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: https://medium.com/@vipra_singh/llm-architectures-explained-encoder-decoder-architecture-part-4-b96ace71394c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the above figure, we have total 4 LSTMs in Encoder and another 4 LSTMs used in Decoders. The underlying RNN we use in the Encoder-Decoder is the LSTM. \n",
    "\n",
    "Now, lets perform a language translation technique where the input is in English and the output string should be converted to French language. Hence we need to first train the model with the English to French dataset containing good amount of training data. \n",
    "\n",
    "Consider our training dataset has one record containing \"I am a student\" then lets see how it get processed in the Encoder-Decoder architecture step by step. \n",
    "\n",
    "1. For example, we have four LSTMs declared and each word in the above sentence gets splitted [\"I\", \"am\", \"a\", \"boy\"] and gets passed individually into each LSTM.\n",
    "\n",
    "2. They will be converted into Word embeddings we can use any technique available such as One hot encoding, Bag of words, Word2Vec, or Embedding layer and gets passed to the LSTMs. \n",
    "3. Now, the LSTMs will remember the context and the output from one LSTM will be passed to another and so on till the end or until the <EOS> ~ <End of Sequence> is passed. \n",
    "4. Once the whole input is completed, Encoder will output the **Context Vector**. Remember, we will not focus on each output of the LSTM in the encoder instead we will get only one output. \n",
    "5. The context vector gets passed into the Decoder layer, and we often use the tab space to define the start of the string or sequence while training the dataset. \n",
    "6. The first character taken from the context vector gets passed after getting converted into Embedding, and we will apply the activation function of our choice and Dense layer we will get the output in French language. \n",
    "7. The same output sent by first LSTM is passed on to the next LSTM in the decoder after getting converted into embedding. This process repeats until the control reaches the end of string/sequence. \n",
    "8. The same step repeats until all the sentences in the dataset are trained completely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test input passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a test input is passed the outputs received from Decoder layer will be of $\\hat{y_1}$,  $\\hat{y_2}$,  $\\hat{y_3}$, ... $\\hat{y_n}$. Then we will compute the probability of the predicted outputs received aganist the trained inputs. \n",
    "\n",
    "We will then calculate the loss function and apply the optimizer to reduce the loss value. Usually we will use the help of Adam optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the LSTM solves some of the major use cases like language translation, it is still unable to show good accuracy for the sentences which are very lenghthy. \n",
    "\n",
    "Longer the sentences, lesser the accuracy. \n",
    "\n",
    "We use the help of **BLEU (Bi-Lingual Evaluation Understudy) score**, which evalulates the accuracy of the sentences which are translated from one language to another using the help of the reference sentences and with n-grams."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
