{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen - AgentChat \n",
    "\n",
    "Using AgentChat, we can quickly build agentic applications using preset agents.\n",
    "\n",
    "In this notebook, let us start buildiong a single agent which uses tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of `agentchat` and `ext[openai]` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.6.4)\n",
      "Requirement already satisfied: autogen-core==0.6.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-agentchat) (0.6.4)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (1.35.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (11.0.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (2.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-agentchat) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.4->autogen-agentchat) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.4->autogen-agentchat) (2.27.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.4->autogen-agentchat) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.4->autogen-agentchat) (3.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"autogen-agentchat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-ext[openai] in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.6.4)\n",
      "Requirement already satisfied: autogen-core==0.6.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-ext[openai]) (0.6.4)\n",
      "Requirement already satisfied: aiofiles in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-ext[openai]) (24.1.0)\n",
      "Requirement already satisfied: openai>=1.66.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-ext[openai]) (1.97.1)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-ext[openai]) (0.9.0)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (1.35.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (11.0.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (2.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from autogen-core==0.6.4->autogen-ext[openai]) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.4->autogen-ext[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.4->autogen-ext[openai]) (2.27.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.66.5->autogen-ext[openai]) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.4->autogen-ext[openai]) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.4->autogen-ext[openai]) (3.23.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Gemini LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Defining the model_client with Gemini 1.5 Flash 8B\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-1.5-flash-8b\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = await model_client.create([UserMessage(content=\"What is the capital of India?\", source=\"user\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Fake function call for Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent # Importing Assistant agent \n",
    "from autogen_agentchat.ui import Console # Importing Console UI\n",
    "\n",
    "weather_agent = AssistantAgent(\n",
    "    model_client=model_client,\n",
    "    name=\"weather_agent\",\n",
    "    tools=[get_weather],  # Registering the get_weather tool\n",
    "    system_message=\"You are a helpful weather assistant. You can provide the current weather for any city using the get_weather tool.\",\n",
    "    reflect_on_tool_use=True,  # Enabling reflection on tool use\n",
    "    model_client_stream=True,  # Enabling streaming responses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in San Francisco?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='', arguments='{\"city\":\"San Francisco\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in San Francisco is 73 degrees and Sunny.', name='get_weather', call_id='', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The weather in San Francisco is 73 degrees and sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def main() -> None: \n",
    "    # Running the agent in a console UI\n",
    "    await Console(weather_agent.run_stream(task=\"What is the weather in San Francisco?\"))\n",
    "    await model_client.close()\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
