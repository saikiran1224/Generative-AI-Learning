{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Generative AI\n",
    "\n",
    "Generative AI is an Artificial Intelligence that is capable of creating or generating text, images and other types of content. Anyone can easily interact with Generative AI with just an text input or prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Year | Name | Explanation |\n",
    "| --- | --- | --- |\n",
    "| 1960 | Artificial Intelligence | Chatbots used to depend on the Knowledge base, but scaling made it difficult. | \n",
    "| 1997 | Machine Learning | Machines are capable of identifying the trends or patterns in the data without explicit programming. | \n",
    "| 2017 | Deep Learning | Advancement in the hardware improved computational power, resulting in development of Neural Networks resembling Human brain like structure. | \n",
    "| 2021 | Generative AI | Capable of creating text, visual and music content using the prompts. Developed using Transformer Architecture | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture has overcomed the main drawbacks of Recurrent Neural Networks (RNNs).\n",
    "\n",
    "- Trasformers are able to accept large text sequences as input. \n",
    "\n",
    "- They work based on the Attention mechanism. \n",
    "- Transformers assigns/calculates the weights to the text in the given input sentence which it thinks more attention should be paid. In short, it pays more attention when the most relevant information is concentrated. \n",
    "- These weights are calculated irrespective of the order of the words in the input sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is one of the most recent Generative AI model used for text-to-text related tasks. These models takes input as text and outputs the data in form of text. \n",
    "\n",
    "Training of these LLMs are trained on huge amounts of unlabeled data from diverse sources like books, articles and websites, etc.\n",
    "\n",
    "These are capable of handling wide variety of tasks such as creating human-like content in more creative manner in correct grammatical order. \n",
    "\n",
    "This enabled the LLMs in two ways: \n",
    "\n",
    "1. Able to understand the human text and the context of the sentence.\n",
    "\n",
    "2. Enabled to give the response in Human language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a high-level, three main steps are involved. Let us understand each step in brief. \n",
    "\n",
    "#### Step 1: Tokenizer - Text to numbers\n",
    "\n",
    "Consider a sentence is given as input to the LLM, before passing the same to the LLM the given input sentence gets break down into tokens of variable length, and later getting converted into numbers. Being statistical models, they work much better with numbers rather than text. \n",
    "\n",
    "A token is defined as a chunk of text. Whenever an input sentence is passed it gets breaken down into a arrays of tokens. Post tokens are splitted, each token is mapped with a token index which is the integer encoding of the original text chunk. \n",
    "\n",
    "Input text -> TOKENIZER -> Core model (LLM)\n",
    "\n",
    "\n",
    "#### Step 2: Predicting Output tokens\n",
    "\n",
    "Consider n number of tokens are passed as an input to the model, then the model will give one token as output. The same token gets passed as an input to the next iteration and the same continues till the end of response in an expanding window manner. This way improves the human experience of seeing one (or multiple) sentence as an answer. Hence, sometimes if you have seen that model gets stopped in the middle of sentence.\n",
    "\n",
    "\n",
    "#### Step 3: Selection process and Probability distribution\n",
    "\n",
    "The output token is chosen by the model based on the probability of occuring after the current text sequence. Model predicts the probability distribution of all the possible \"Next tokens\". The token with the highest probability value will be chosen for the output. But it wont be the same all the time, because \"Degree of randomness\" is added which makes sure that the output will differ even for the same input. \n",
    "\n",
    "This Degree of randomness is added to improve the creativity of the model, where we can control the same using the help of the model parameter called 'Temperature'."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
