{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI Project Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop any project from scratch, we need to have a project lifecycle initially to be set which we can follow for developing. Similarly, Generative AI also has one lifecycle. \n",
    "\n",
    "Lets discuss about the same now, with its lifecycle diagram shown below: \n",
    "\n",
    "![GenAI Project Lifecycle](https://miro.medium.com/v2/resize:fit:1400/1*aAIOytDfedwuFLoG7qbn8Q.png)\n",
    "\n",
    "<a href=\"https://miro.medium.com/v2/resize:fit:1400/1*aAIOytDfedwuFLoG7qbn8Q.png\" target=\"_blank\">Image Source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand deeply about each phase. \n",
    "\n",
    "## 1. Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Initial phase in the lifecycle where we will define the Project Use case and define the scope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second phase where in which we need to \"Select\" the model. \n",
    "\n",
    "Based on our usecase, we need to check if we can leverage already trained Foundation model or we need to pre-tune a model. Most cases, people goes with already available Foundational model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adapt and align model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an Important phase, where we need to make our model adapt with our responses and evaluation is done. \n",
    "\n",
    "As we can see on the above figure, \n",
    "- First we will use the help of \"Prompt Engineering\" to get our desired response and then Evaluate the same. \n",
    "\n",
    "- If its not satisfied, then we will try \"Fine-tuning\" the model and again try the Prompt Engineering and evalulate.\n",
    "- This cycle repeats until the model responses are as expected. Once the required steps are done, the final step will be performed. \n",
    "- We need to make sure our model responses are aligned with the human feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final phase in which we are going to integrate our LLM model into our application using the available infrastructure.\n",
    "\n",
    "We need to perform two things to here to build a powerful LLM application. \n",
    "- If required, model needs to be optimized and then deployed for inference. \n",
    "\n",
    "- We can augument the model and finally build our LLM-powered application."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
