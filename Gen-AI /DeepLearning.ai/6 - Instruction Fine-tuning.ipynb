{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before understanding about fine-tuning, let us have a look on the drawbacks of the in-context learning. \n",
    "\n",
    "## Drawbacks of In-context learning\n",
    "\n",
    "- Smaller models with less parameters will not be able to understand the in-context learning as they are already trained on less amount of data and lacks the ability to idenify the patterns. \n",
    "\n",
    "- Context window will be filled with this examples leaving no space for the instructions to be filled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Instruction fine-tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome these drawbacks, we need to \"Fine-tune\" the model. \n",
    "\n",
    "- If we remember, in pre-training process of LLM we have trained with Petabytes, Terabytes and Gigabytes of data. \n",
    "\n",
    "- Similar to that, in fine-tuning we will have a labeled dataset of the same or less size, and using the supervised learning technique we will fine tune the model. \n",
    "\n",
    "- Our labeled dataset contains lots of Task specific examples (Prompt and Completion pairs) which are related to one or multiple tasks.\n",
    "\n",
    "- Our LLM model gets re-trained from scratch using our labeled dataset, and all the model weights and parameters are updated. This process is called as \"Full Fine-tuning\". \n",
    "\n",
    "- This process improves the model performance and releases a new version of LLM model. \n",
    "\n",
    "- Prompt libraries are designed to fine-tune models for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Full fine-tuning requires full compute and memory as compared to pre-training of LLM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps involved in Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Prepare and clean the dataset.\n",
    "\n",
    "**Step 2:** Perform Train, test and split the dataset for training and testing purpose.\n",
    "\n",
    "**Step 3:** Use the training dataset, and fine-tune the LLM model. \n",
    "\n",
    "**Step 4:** We need to use the \"Cross Entropy\" loss function to optimize the output and parameters. The weights gets automatically updated in the standard backward propogation and after multiple EPOCHs the values will be updated. \n",
    "\n",
    "**Step 5:** Once the training is successfull, we can evalulate the model using our testing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Task Fine-tuning\n",
    "\n",
    "While fine-tuning the LLM model only for a single task, we often need 500-1000 set of examples which will be our training dataset. But doing the same, it leads to a problem called \"Catastrophic forgetting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Catastrophic forgetting? \n",
    "\n",
    "- This is a phenomenon occurs post fine-tuning the LLM model for a single task. \n",
    "\n",
    "- This leads the LLM model to forget its original capabilities/earlier tasks such as doing generic operations i.e., Generation, Summarization, etc. and only works good for the single-task that is fine-tuned on. \n",
    "\n",
    "- Below example shows more explainable information: \n",
    "\n",
    "    | Status | Prompt | Completion |\n",
    "    | :---: | :---: | :---: |\n",
    "    | Before fine-tuning | What is cat name? Charlie the cat is on bed. | *Charile* |\n",
    "    | After fine-tuning | What is cat name? Charlie the cat is on bed. | *Charile is positive* |\n",
    "\n",
    "### Solution to avoid this problem\n",
    "\n",
    "- First solution is to train the model on multiple tasks instead of single task. \n",
    "\n",
    "- By leveraging Parameter Efficient Fine-tuning (PEFT) - it doesn't change the original parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Task Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training dataset contains examples of several tasks, where each task is associated with several examples.\n",
    "\n",
    "- Using this technique, we can avoid the problem of catastrophic forgetting. \n",
    "\n",
    "#### Drawbacks: \n",
    "\n",
    "- Requires lots of data nearly 50,000 records of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAN-T5 LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FLAN-T5 termed as \"Fine-tuned Language Net -T5\" defines the process involved in Instruction fine-tuning. \n",
    "\n",
    "- This model is an instruction fine-tuned version of T5 model, a Text-to-Text Transfer Transformer which is fine-tuned on 1000 multiple tasks. \n",
    "\n",
    "- Its main area involves in working with various NLP related tasks converting them into a text-to-text format.\n",
    "\n",
    "- When compared with the original T5 model, FLAN-T5 works more better on Question answering, Translation, Summarization, etc. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
