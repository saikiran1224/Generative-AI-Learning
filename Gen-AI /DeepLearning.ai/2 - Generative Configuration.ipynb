{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous module, we have learned about the Prompting techniques and the three types of inferences when using the prompts. Here, let us understand about the Generative Configuration. \n",
    "\n",
    "We can fine tune or modulate the responses by adjusting some parameters of the LLMs which will be automatically invoked during the inference. There are mainly three parameters which can be adjusted, they are: \n",
    "\n",
    "1. Max New Tokens\n",
    "\n",
    "2. Temperature\n",
    "3. Top_p\n",
    "4. Top_k\n",
    "\n",
    "There were many articles on the Internet mentioning about these three parameters. Remember, tuning these parameters will directly affect and control our LLM responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max New Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parameter defines the maximum number of tokens the LLM can generated. In short, the number mentioned here will be the number of the tokens LLM can limit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before understanding about the next three parameters, let us understand about two terms - Greedy and Random Sampling. \n",
    "Basically the LLM contains a large dictionary, and in the final output it will generate a dictionary associated with their corresponding probabilties. Its with the LLM to choose the next token based on this inference.\n",
    "\n",
    "### Greedy Sampling \n",
    "This a sampling technique in which the LLM selects the word or token with the highest probability from the given dictionary. \n",
    "\n",
    "### Random Sampling\n",
    "This is a sampling technique in which the LLM chooses a token or word using a 'Random Weighted Strategy' across the probability of all the tokens.\n",
    "\n",
    "By default all the LLMs uses the Greedy Sampling and chooses the token/word with the highest probability as the next token. We need to explicitly set, if we are going to use the Random Sampling Technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its a setting that will be applied at the Softmax Layer. \n",
    "\n",
    "**Higher the temperature, the more creative the responses are, and lesser the temperature the respones are precise.**\n",
    "\n",
    "Most models have the temperature values lie between (0 - 1 or 2) sometimes. What happens inside the model, if we vary the temperature value? \n",
    "\n",
    "- Higher Temperature (>=1) - Broader and Flattens the probability distribution. (Probability gets even spread)\n",
    "\n",
    "- Lesser Temperature (<1) - Strongly peaked Probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top_k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"k\" is a famous parameter used in terms of Probability distribution. In terms of LLM, this parameter plays a major role. As we already know that LLM will generate a big dictionary containing the tokens associated with their probabilities.\n",
    "\n",
    "Top_k selects the top \"k\" results, from the output received after applying Random sampling weighted strategy using the probabilties. \n",
    "\n",
    "E.g., if `top_k = 3`, then it selects the first top-3 tokens randomly from the output dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parameter selects the output using the Cumulative Probability, by applying Random Weight Sampling for the top-ranked consecutive results. \n",
    "\n",
    "E.g., if `top_p = 0.5`, then the first consecutive tokens summing upto 0.5 will be chosen. For instance, 0.3 + 0.1 + 0.1 - these tokens will be generated. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
