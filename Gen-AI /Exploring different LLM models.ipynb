{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Different LLM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs are differntiated based on many aspects. Be it Architecture, Training data and use case, etc. Its very important to chose the right LLM model based on our use case or the project that we are trying to develop. \n",
    "\n",
    "Lets see some basic model types based on some use-cases: \n",
    "\n",
    "### 1. Audio and Speech Recognition\n",
    "We can use Whisper-type models for this purpose. These models helps us to recognize the voice in various different languages which it was trained upon. \n",
    "\n",
    "These models are trained on diverse audio and can perform multi-lingual speech recognition. \n",
    "\n",
    "### 2. Image Generation\n",
    "Dall-E, Bing Image creator and Midjourney were one of the famous models which can be used for Image creation. DALL-E is an offering by OpenAI.\n",
    "\n",
    "### 3. Text Generation\n",
    "There are many models available in the market which is capable of producting text as an output. OpenAI's GPT 3.5 to 4.0 is one of the latest model. \n",
    "\n",
    "GPT 4.0 is expensive model and GPT 3.5 comes at good price. \n",
    "\n",
    "### 4. Multi-modality\n",
    "\n",
    "It means the same model is capable of doing multiple tasks. The latest releases of OpenAI models which are capable of combining visual understanding text based.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundation Models vs LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Foundation models are considered as a Superset and LLMs are part of Foundation model like a Subset. \n",
    "\n",
    "- Foundation models (FMs) are trained on large versatile data and they are trained using either **Unsupervised Learning or Self-supervised learning**. \n",
    "\n",
    "- These Foundation models are **capable of handling different types of modalities including Images, Audio, text, etc.**\n",
    "\n",
    "- These models are developed using **Complex Deep Neural Networks with Billions of parameters**. \n",
    "\n",
    "- All the other models are built on-top of these Foundation models meaning they can be used as a starting point for other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Source vs Proprietary Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs can also be categorized in the other way like either it can be Open source or properietary model. Below are some of the key differences between both the models. \n",
    "\n",
    "| Open Source models | Proprietary models | \n",
    "| ---- | ----- | \n",
    "| Available to use for Free by Public | Available for use on subscription basis or cost-based |\n",
    "| Not suitable for Production usage | Suitable for Production usage |\n",
    "| Able to customize, inspect and modify as required | Will not be able to customize, inspect and modify as required |\n",
    "| Users can further train the model with own data | Users will not be able to train the model with own data | \n",
    "| Will have control on the data | Need to completely trust on the model provider |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vs Image Generation vs Text and Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding models:**\n",
    "The purpose of these models is to convert the text data into numerical form so that it will be easy for machines to understand the context and can easily compare with the other sentences. These numerical representation of texts can be used in classification models or clustering models as per the purpose. \n",
    "\n",
    "These models are often used for Transfer learning. Transfer learning in short words, consider there is a perfectly trained model. Now, our use case is to train a model with something similar as our previous model in that case we can use this model as our starting point and can train again on top of that instead of doing the same from scratch.\n",
    "\n",
    "\n",
    "**Image Generation models:**\n",
    "These models generate images as output. These are often used for image editing, synthesis and image translation. \n",
    "\n",
    "These models are trained on huge images dataset and are used to generate new images, or to customize old image, etc. \n",
    "\n",
    "**Text and Code Generation models:**\n",
    "These are the models which generate text or code. These can help us in generating new text, summarization, translation and acting like a chatbot. These models are trained on huge data. \n",
    "\n",
    "Code generation models such as Github co-pilot, etc. are trained on lots of user written code. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
