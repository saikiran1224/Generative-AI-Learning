{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Different LLM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs are differntiated based on many aspects. Be it Architecture, Training data and use case, etc. Its very important to chose the right LLM model based on our use case or the project that we are trying to develop. \n",
    "\n",
    "Lets see some basic model types based on some use-cases: \n",
    "\n",
    "### 1. Audio and Speech Recognition\n",
    "We can use Whisper-type models for this purpose. These models helps us to recognize the voice in various different languages which it was trained upon. \n",
    "\n",
    "These models are trained on diverse audio and can perform multi-lingual speech recognition. \n",
    "\n",
    "### 2. Image Generation\n",
    "Dall-E, Bing Image creator and Midjourney were one of the famous models which can be used for Image creation. DALL-E is an offering by OpenAI.\n",
    "\n",
    "### 3. Text Generation\n",
    "There are many models available in the market which is capable of producting text as an output. OpenAI's GPT 3.5 to 4.0 is one of the latest model. \n",
    "\n",
    "GPT 4.0 is expensive model and GPT 3.5 comes at good price. \n",
    "\n",
    "### 4. Multi-modality\n",
    "\n",
    "It means the same model is capable of doing multiple tasks. The latest releases of OpenAI models which are capable of combining visual understanding text based.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundation Models vs LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Foundation models are considered as a Superset and LLMs are part of Foundation model like a Subset. \n",
    "\n",
    "- Foundation models (FMs) are trained on large versatile data and they are trained using either **Unsupervised Learning or Self-supervised learning**. \n",
    "\n",
    "- These Foundation models are **capable of handling different types of modalities including Images, Audio, text, etc.**\n",
    "\n",
    "- These models are developed using **Complex Deep Neural Networks with Billions of parameters**. \n",
    "\n",
    "- All the other models are built on-top of these Foundation models meaning they can be used as a starting point for other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Source vs Proprietary Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs can also be categorized in the other way like either it can be Open source or properietary model. Below are some of the key differences between both the models. \n",
    "\n",
    "| Open Source models | Proprietary models | \n",
    "| ---- | ----- | \n",
    "| Available to use for Free by Public | Available for use on subscription basis or cost-based |\n",
    "| Not suitable for Production usage | Suitable for Production usage |\n",
    "| Able to customize, inspect and modify as required | Will not be able to customize, inspect and modify as required |\n",
    "| Users can further train the model with own data | Users will not be able to train the model with own data | \n",
    "| Will have control on the data | Need to completely trust on the model provider |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vs Image Generation vs Text and Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding models:**\n",
    "The purpose of these models is to convert the text data into numerical form so that it will be easy for machines to understand the context and can easily compare with the other sentences. These numerical representation of texts can be used in classification models or clustering models as per the purpose. \n",
    "\n",
    "These models are often used for Transfer learning. Transfer learning in short words, consider there is a perfectly trained model. Now, our use case is to train a model with something similar as our previous model in that case we can use this model as our starting point and can train again on top of that instead of doing the same from scratch.\n",
    "\n",
    "\n",
    "**Image Generation models:**\n",
    "These models generate images as output. These are often used for image editing, synthesis and image translation. \n",
    "\n",
    "These models are trained on huge images dataset and are used to generate new images, or to customize old image, etc. \n",
    "\n",
    "**Text and Code Generation models:**\n",
    "These are the models which generate text or code. These can help us in generating new text, summarization, translation and acting like a chatbot. These models are trained on huge data. \n",
    "\n",
    "Code generation models such as Github co-pilot, etc. are trained on lots of user written code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to improve LLM Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mainly four ways to improve LLM Results. They are as stated below: \n",
    "\n",
    "- Prompt Engineering with Context (LLM model)\n",
    "\n",
    "- Retrieval Augumented Generation (RAG)\n",
    "- Fine tuned model\n",
    "- Trained model\n",
    "\n",
    "From top to bottom, difficulty and the cost increases. Trained model provides with highest quality and Prompt Engineering provides low quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand about each and every way in detail. First lets start with Prompt Engineering. \n",
    "\n",
    "### 1. Prompt Engineering with Context (LLM model)\n",
    "\n",
    "To improve our LLM results, we should write the prompt in such a way that it is giving the useful context to generate a response. However, the main drawback of LLMs are it has only the knowledge of its training data but not the current data. \n",
    "\n",
    "But we can try getting better response, by refining our prompts further. They are divided into three types: \n",
    "\n",
    "#### Zero-shot learning\n",
    "If our prompt is a single complete sentence or small phrase, then it is called as Zero-shot learning. Here we are not providing any examples in our prompt for the model to understand. \n",
    "\n",
    "#### One-shot learning\n",
    "To provide more context to the model, if our prompt contains one example to make the LLM understand better then its called as One shot learning. \n",
    "\n",
    "#### Few-shot learning \n",
    "Similar to the above one-shot learning if our model is prompted with multiple examples then its called as Few shot learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieval Augumented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of RAG overcomes the drawback of the LLM where it doesnt have the memory of current data. Even we can't train the whole model with the new data which is very difficuly and expensive. Also, consider there are use-cases where the company wants to use the LLM but it can't share its confidential data to the Internet.\n",
    "\n",
    "The short and simple task is to employ the technique of RAG. Consider our data is stored in the database or available at the web endpoint. RAG is a technique where-in it \"Auguments the prompt with external data in form of chunks based on the prompt length limit\". \n",
    "\n",
    "This can be implemented using Vector Database where it stores all the chunks of data, and it helps in easily associating the same with the prompts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fine-tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning is a process where we will use \"Transfer learning\" technique to enhance an already existing model with the new training data. \n",
    "\n",
    "This process eliminates the model to train from scratch instead we are training the same model again on top of that. We will get the output of a better model with improved biases and weights. Compared to RAG, this provides better results in terms of results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Trained model\n",
    "\n",
    "Training an LLM from scratch will be the highest complex and expensive task. To train an LLM from scratch, we need to have lots lots of data which is perfectly cleaned and transformed. We need high computational power to train the model. \n",
    "\n",
    "But if the company has domain-specific use case and large amount of data then training model from scratch is preferred else its of no use. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
