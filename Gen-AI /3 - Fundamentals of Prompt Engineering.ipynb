{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Prompt Engineering\n",
    "\n",
    "In the era of Generative AI, prompts are something which plays a major role in the interaction with the LLM model. Lets understand from the sratch how the prompt engeering works and everything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Prompt Engineering? \n",
    "\n",
    "Prompt Engineering is defined as the process of \"Designing\" and \"Optimizing\" text inputs a.k.a prompts to get the desired results from the model. By refining the prompts, we can make the model deliver consistent and well-formatted results. \n",
    "\n",
    "There is a 2-step process involved here:\n",
    "1. Initially, the prompt should be designed.\n",
    "\n",
    "2. Refining the prompt further to refine/improve the quality of the results.\n",
    "\n",
    "This is a trial-and-error process which requires user involvement and will be continuous until we get a desired output or result as we expect. \n",
    "\n",
    "But did we think why do we need to refine our prompts all the time? To understand the same, we need to first know about three important terms. \n",
    "\n",
    "1. **Tokenization** - how our \"prompt\" gets transformed\n",
    "\n",
    "2. **Base LLMs** - how the \"prompts\" gets processed further\n",
    "3. **Fine-tuned LLMs/Instruction-tuned LLMs** - how model is able to identify \"tasks\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each and every LLMs has its own different process of tokenization. \n",
    "\n",
    "Mostly, LLMs consider prompts like sequence of tokens combined together and breakdown of the given sentence into token varies from model to model. \n",
    "\n",
    "All the LLMs are trained on tokens, hence breaking the given sentence into tokens and passing on to the model gives us a better result. We can try playing with the available [OpenAI tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Foundation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foundation models are also called as Base LLMs. These models main role is to just predict the next token in the sentence. \n",
    "\n",
    "Base LLMs doesnt have any understanding of the given token meaning. Since it is trained on the sentences, its role is just to predict the next words in the sequence. This process continues until and unless there is a human intervention or any specified condition mentioned to stop the response. \n",
    "\n",
    "If we give any information to the model, it will consider it as request and give the same output again in an formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instruction Tuned LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the LLMs which are built on top of the Foundational LLMs. The base models are getting fine-tuned with the training data and then those models will act like Instruction-tuned LLMs or Fine-tuned LLMs. \n",
    "\n",
    "Reinforcement Learning or Transfer learning is used to train the underlying model further with the company specific or new data. Hence, it results in better data and outputs. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
