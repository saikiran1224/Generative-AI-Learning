{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier and Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks of Decision Tree Alogorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deep diving into Random Forest, let us have a look on the drawbacks or challenges of the Decision Tree algorithm: \n",
    "- Performs Overfitting (model works good for Training data showing Low bias and High variance)\n",
    "- Pruning can be done but its difficult.\n",
    "- Will not be able to handle outliers.\n",
    "\n",
    "Random Forest will help us to overcome all the above stated drawbacks and helps us to develop a generalized model (Low bias and Low Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a bagging algorithm. As discussed earlier in bagging concept, we will be sampling the features and data points in our dataset and provide it to multiple models and train them individually. \n",
    "\n",
    "Once the test input is given to all the models, the predicted output will be considered the majority. This is called as Majority voting or bootstrap aggregator. Here, in Random Forest all the models will be Decision Trees only. \n",
    "\n",
    "It will be Decision Tree 1, Decision Tree 2, etc. so on and so forth."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
