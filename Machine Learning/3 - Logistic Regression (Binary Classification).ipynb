{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Binary Classification)\n",
    "\n",
    "This is part of Supervised Learning > Classification problem. \n",
    "\n",
    "The output of this model will be fixed and here we will be dealing with two values as its a binary classification. This algorithm works well with Multi-classification as well. \n",
    "\n",
    "Eg. No. of study hours vs Pass/Fail \n",
    "\n",
    "Likewise Linear Regression, we can plot the data points over a graph and find the best fit line for the above example. But it works fine for all the given data, but the best fit line fails when there is a **Outlier** or when a new **input/test data** is passed to the model.\n",
    "\n",
    "But there were some drawbacks identified or how linear regression is not suitable here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks if we use Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon using the best fit line of linear regression, it will be a line passing through origin and it will pass to the points as per the given training data. But there is a catch here, once if we give a new input to the model which is far to the best fit line then automatically due to the long distance a new best fit line will be formed which affects the earlier values. \n",
    "\n",
    "It means, the new best fit line which is formed will show the previous values where the output is True as False, which is completely not accepted. To overcome this drawback with the Linear regression, we need to squash (make the line straight) so the output will be as expected. \n",
    "\n",
    "For squashing the line, we will be using the help of Sigmoid function which will be applied on the already present cost function of linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps us to squash the best fit line. Since the main objective of Logistic regression is the output values should be between 0 and 1. So lets derive the same.\n",
    "\n",
    "Consider we know the equation of the best fit line:\n",
    "\n",
    "h $\\theta(x)$ = $\\theta_0$ + $\\theta_1$ * (x) where h $\\theta(x)$ is the predicted value. \n",
    "\n",
    "So let z = $\\theta_0$ + $\\theta_1$ * (x), then we can derive the above equation as follows: \n",
    "\n",
    "h $\\theta(x)$ = g(z) \n",
    "\n",
    "h $\\theta(x)$ = 1 / (1 + $\\exp^{-z}$) \n",
    "\n",
    "then h $\\theta(x)$ = 1 / (1 + $\\exp^{-(theta_0 + theta_1 * (x)}) $\n",
    "\n",
    "So if we draw a graph for the above function then we can observe that g(z) $\\geq$ 0.5 when z $\\geq$ 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking feasibility of Linear Regression Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the training data as (x1, y1), (x2, y2), (x3, y3), ... (xn, yn). Here remember that y will lie between 0 and 1. \n",
    "\n",
    "Remember the cost function of linear regression, \n",
    "\n",
    "J($\\theta_0$, $\\theta_1$) = 1 / 2m * $\\sum_1^m$ (h $\\theta(x^i)$ - y^i) ^ 2\n",
    "\n",
    "here we will replace the h $\\theta(x^i)$ with the sigmoid function which we derived above, then the final function will be the h$\\theta(x^i)$ replaced by the sigmoid function 1 / (1 + $\\exp^{-(theta_0 + theta_1 * (x))}) $.\n",
    "\n",
    "But, the function which was derived just now is a **Non-convex function** which is not suitable to find the global minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between Convex and Non-Convex functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convex Function** - This a function in which its in the shape of Gradient Descent and there will be a point where there is Global minima. Remember, in Linear regression the cost function graph will look like the same which helps us to easily identify the best fit line. \n",
    "\n",
    "**Non-Convex Function** - This is a function in which the graph is irregularized and it has multiple local minimas making the model to not work properly and also not able to find the best fit line at the point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, since the above derived function is a Non-Convex function we will not be proceeding with this ahead. \n",
    "\n",
    "But as per the researcher, the final **Cost Function of Logistic Regression** is mentioned below considering $\\theta_0$ = 0.\n",
    "\n",
    "J($\\theta_1$) = -$\\log( h \\theta(x^i)$) when y = 1\n",
    "\n",
    "J($\\theta_1$) = -log(1 - h $\\theta(x)$) when y = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the logistic regression model, we have total three kinds of performance metrics which helps us to assess the model performance and accuracy. They are:\n",
    "\n",
    "- Precision\n",
    "- Recall \n",
    "- F score\n",
    "\n",
    "Before discussing about all the above performance metrics, lets discuss about the **Confusion Matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Confusion Matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is matrix kind of structure where it will help us to assess the classification model, by intelligently comparing the predicted and actual values. \n",
    "\n",
    "As shown below, the actual values will be mentioned on the top, and the predicted values on the left. Inside the matrix, the count is calculated based on the terms (TP, FP, TN, FN). Lets learn more about them one by one with an example: \n",
    "\n",
    "Consider an example of pregnancy: \n",
    "\n",
    "**True Positive (TP) - 11 :** Both the actual and predicted values says lady is pregnant.\n",
    "\n",
    "**False Positive (FP) - 10 :** Actual value says not pregnant but predicted values says lady is pregnant.\n",
    "\n",
    "**True Negative (TN) - 01 :**  Actual value says pregnant but predicted values says she is not pregnant. \n",
    "\n",
    "**False Negative (FN) - 00 :** Both the actual and predicted values says lady is not pregnant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Trick:</u> Consider True Positive. \n",
    "\n",
    "'True' refers to the actual value, and whereas 'Positive' value refers to the predicted value. Hence in shortcut we can refer as 1(Pred) 1(Actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://miro.medium.com/v2/resize:fit:712/1*Z54JgbS4DUwWSknhDCvNTQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is defined as the ratio of True Positives to the sum of True Positives and False Positives. \n",
    "\n",
    "Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is defined as the ratio of True Positives to the sum of True Positives and False Negatives.\n",
    "\n",
    "Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Precision** will be used when we are working with Spam classification. Because misidentification of a spam email as not a spam email is not expected. **Recall** will be used when we are working with Medical diagnosis, since the model should not wrongly predict that even if patient is having a disease, it will predict as False. Its fine if it predicts some false positives like even if there is no disease model predicts as +ve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score helps us to evaluate the overall peformance of the classification model. It is defined as the harmonic mean of the Precision and Recall. \n",
    "\n",
    "F1 score = 2 * Precision * Recall / (Precision + Recall)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
