{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A real-life example of Ensemble is a group of singers, dancers, actors, etc. In the similar fashion in Machine Learning we can group different types of models together better output rather than depending on a single model. \n",
    "\n",
    "Its always better to learn something with a group of learners rather than a single learner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To group machine learning models together and get the best output we have two ensemble techniques. They are:\n",
    "- Bagging\n",
    "- Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume we have models M1 (Logistic), M2 (Decision Tree), M3 (KNN), etc. so on and so forth and also a fresh dataset consisting of nearly 10,000 samples. \n",
    "\n",
    "Bagging means its the **process of sampling the data into some random points like d' (1000 - 2000), d'' (2001 - 3000), d''' and passing on them to the models M1, M2, M3, etc. for training.** So in short these models gets trained on the sampled data passed from the dataset. \n",
    "\n",
    "Now, once all the models are perfectly trained and a new test data input is passed to all the models, its expected that all the models may give different outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that 60% of the models predicted 'Yes' and 40% of the models predicted 'No'. Then as per the majority voting we will consider the final predicted output as 'Yes'. \n",
    "\n",
    "This process of considering the majority output is called as **Bootstrap Aggregator**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In real-time there will be 100s of models will be used so there will not be a situation where 50% of models predict 'Yes' and the other 50% models predict as 'No'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the models provides their outputs for the test data passed, since its a regression problem the outputs will be in form of a continous variable. \n",
    "\n",
    "To get the finalized output, we will **perform a Mean or Average for all the predicted values** by the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms used for Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classification\n",
    "- Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its the process of sequentially combining models together to get a improvised output. The models which are combined here are termed as **Weak learners**. \n",
    "\n",
    "The term Weak learner represents a model which is not capable of doing the tasks on its own and also unable to predict the values correctly. Boosting is a technique where in which we will combine all the weak learners sequentially to get a **Strong learner**. \n",
    "\n",
    "Once the test data is passed, after sequentially passing through all the models we will get the best improvised output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms used for Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaboost\n",
    "- Gradient\n",
    "- Xgboost (Extreme Gradient Boosting)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
