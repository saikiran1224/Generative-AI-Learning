{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Algorithm\n",
    "\n",
    "This is one of the popular algorithm in Machine Learning. It is a supervised ML algorithm which works for both regression and classification. But mostly we use it for classification use cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Aim of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the logistic regression, we need to find a best fit line/hyperplane which perfectly divides the dataset into two different classes. \n",
    "\n",
    "Consider our dataset has two different output classes, then the main aim of the SVM algorithm is to identify a hyperplane which divides both the classes with the maximum margin in between. \n",
    "\n",
    "The main hyperplane which divides both the class should be divided in such a case that there is maximum margin between both the datapoints of two output classes. This hyperplane is called as **Maximum margin hyperplane** or **Hard marginal plane**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Key terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below image is the representation of how the SVM algorithm works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://images.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm.png)\n",
    "\n",
    "*Image Credits: <a href=\"https://www.javatpoint.com/machine-learning-support-vector-machine-algorithm\">Javatpoint article</a>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vectors are the data points in the graph which are closest to the hyperplane. These are the vectors which support the hyperplane, hence they are named as Support vectors. \n",
    "\n",
    "The hyperplane will be created in such a way that it has the maximum margin from the support vectors on both the sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Margin Hyperplane or Hard marginal plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, this is a hyperplane which divides both the data points (Support Vectors) with the maximum margin in between both of them which helps in good prediction of the model.\n",
    "\n",
    "Remember that the dimensions of the hyperplane depends on the features present in the dataset. In the above picture, X1 and X2 are two independent features, so the hyperplane is a Straight line. Similarly if the dataset has 3 features, then the hyperplane will be a 2-Dimensional plane.\n",
    "\n",
    "But always irrespective of the features, a hyperplane should have the maximum margin/maximum distance from the datapoints. The equation of the hyperplane is given by $\\ wx + b = 0$. It is derived from the equation of the straight line $\\ ax + by + c = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Marginal plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are cases when due to outliers, data points of one class may overlap on the other plane respectively. For example, in the above graph, if the blue colored squares falls on the -ve hyperplane, and similarly green color circles falls on the +ve hyperplane. Then such type of plane is called as Soft marginal plane. \n",
    "\n",
    "To solve this problem while training the model, we will use the help of some hyperparameters called as $\\eta$ (eta) where we will sum up all these wrong parameters together and sum up with the main cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its the boundary line which lies on the positive side of the graph and passes through the support vectors on the positive side.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the contrary of the positive hyperplane, negative hyperplane is a boundary line which lies on the negative side of the graph and passes through the support vectors on the negative side of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of SVM \n",
    "\n",
    "There are two types of SVMs. They are named as follows:\n",
    "\n",
    "1. **Linear SVM:**\n",
    "   If the dataset has two features and the hyperplane is a Straight line.\n",
    "\n",
    "2. **Non-linear SVM:** \n",
    "   If the dataset has more than two features then we need to add a third dimension called z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the model is trained with images of both the Cats and Dogs. An test image is given to the model of an image of Cat. Already the model would have seperated both the cats and dogs class with a straight line using the extreme cases (support vectors), now with the new test data it will compare with the same and provide the output as Cat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
