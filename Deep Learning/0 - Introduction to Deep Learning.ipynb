{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning is subset of Machine Learning. The research of Deep Learning was started long back in the year 1958. The main aim of the Deep learning is to Mimic the human brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI vs ML vs DL vs Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an application built using AI like Netflix, Amazon app, Sophia, etc. \n",
    "\n",
    "In such applications, Netflix uses recommendation system to recommend movies to users based on their search or watch history. Similarly Amazon does the same. Even though the underlying technology is build using Machine Learning, Deep Learning, NLP, etc. the end application will be called as AI application only. \n",
    "\n",
    "Data Science is the study where it will touch all the subjects starting from AI, ML, DL, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Deep Learning is popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main reasons making Deep Learning so much popular: \n",
    "\n",
    "- Large amount of data produced in the market. \n",
    "\n",
    "- Hardware Advancement (NIVIDA), production of high-end graphic cards, etc. making the computational efficiency fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Perceptron (Single Layered Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron is a Single Layered Neural Network, and it is said to be the Simplest possible Neural network. Lets us first understand with the help of a picture: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://www.w3schools.com/ai/img_perceptron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe the above picture, We have the Input layer (x1, x2, x3, x4 and x5), Hidden Layer (only single node in Red color), and the output node (black color at the end). \n",
    "\n",
    "Once the data is sent as Input to the Input layer, it will get processed in the hidden layer (Neural Network) and provides the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time Example of understanding working of Neural Network\n",
    "\n",
    "Let us consider two scenarios in real-time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a camera is shown to a ADULT, he/she will be able to easily identify the object as Camera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How it works?** The (input layer) here will be our eyes, where it will see the object, and pass on the information to the neurons (hidden layer), and they will process and it provides the output to the Brain (Output layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a camera is shown to a NEW BORN, he/she will NOT BE able to identify the object as Camera. \n",
    "\n",
    "**Why?** The answer is simple since the neural network is not trained, so they were unable to answer which item it was. \n",
    "\n",
    "**How to train?** Parents will train the newborn like this is pencil, this is book, this is bottle, this is milk, etc. So in time baby will be able to learn which item it is, as his/her Human Neurological Network is now trained with the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Layer Importance and working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the perceptron, there are three main layers. They are:\n",
    "- Input Layer\n",
    "\n",
    "- Hidden layer (for feasability we have considered only one node)\n",
    "- Output layer\n",
    "\n",
    "Let us understand the tasks which are performed by each layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, Input layer is the layer where in which the data is inserted/passed into the Neural network. \n",
    "\n",
    "In the above picture, we have total 5 types of features (x1, x2, x3, x4 and x5). Hence, we have initialized total 5 nodes. And also, for every input node we need to assign the weights (w1, w2, w3, w4 and w5) while passing the inputs to the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is weights and their importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights basically says that how much the neurons should get activated or deactivated. We will take care of the weights value so that we can control the activation of neuron whether to which level, the neuron should be activated.\n",
    "\n",
    "For example, consider a real-time example, our left hand touched a hot object, then automatically input layer here itself is our hand and its passed to the neurons in the hidden layer. So here, the weights basically regulates the activation of neurons to which level. So here the neurons gets activated very high, and it immediately Brain gives the signal to remove the hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer \n",
    "\n",
    "Inside the hidden layer, there are two main steps are performed which are essential. They are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 \n",
    "\n",
    "Calculation of summation of product of inputs and weights which gives the values of y. (y = $\\sum x_i w_i$ = $\\ w^T x$)\n",
    "\n",
    "Consider a case where the weights were intialized as 0, then the value of y will be equal to 0. \n",
    "\n",
    "To avoid that, we need to add the **Bias** value, which helps the value of $\\ y>0$. Hence the final equation will be $\\ y = \\sum x_i w_i + b= \\ w^Tx + b$ where b is bias. \n",
    "\n",
    "Now, the y value will be passed to the activation function in the Step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Pass the (y = $\\sum x_i w_i$ = $\\ w^T x$) to the Activation function. Remember, there are different types of activation function. \n",
    "\n",
    "For an instance, if our task is related to Binary Classification problem, then we can use the help of **Sigmoid Activation Function** which gives the output only in the range of 0 and 1. \n",
    "\n",
    "As the rule says, if the value of the sigmoid activation function is <0.5 then the output will be 1, else if the value of the sigmoid function says >0.5, then the output will be 1.\n",
    "\n",
    "The final output of the Activation function will be considered as O1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output passed by the hidden layer (O1) will now be multiplied with w4 (Weight added after hidden layer), and now both of get multiplied $\\ O1 w4$, and the same steps which are performed in the hidden layer will be re-performed. \n",
    "\n",
    "Step 1: Calculating the $\\ y = O1w4 + b$ \n",
    "\n",
    "Step 2: Passing the value of y to the Activation function inside the output layer. \n",
    "\n",
    "The final output will be our answer or prediction made by the Neural network for one set of record. This will be termed as $\\ \\hat{y}$ (y hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propogation\n",
    "\n",
    "The whole process which was performed from first to last starting from taking Input to prediction of the value by the Neural network is called as Forward Propogation. \n",
    "\n",
    "In a Neural Network, the following main steps are performed: \n",
    "\n",
    "1. Input features (xi) are passed.\n",
    "\n",
    "2. Input features (xi) are multiplied with weights (wi). \n",
    "3. Bias will be added as required (Neural Network will take care of bias value)\n",
    "4. Activated the Activation function using the value of y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the prediction of the Neural Network as $\\ \\hat{y}$ (Predicted value), and also since its a Supervised Learning model we also have the corresponding truth / actual value of this particular record termed as $\\ y$. \n",
    "\n",
    "For example, as per our dataset the actual value should be 1, but however our neural network predicted as 0 which is completely wrong. Hence, we use the help of **Loss Function** which tells how much is the difference of the actual and predicted values. \n",
    "\n",
    "$\\displaystyle Loss Function = \\hat{y} - y $ = 1 - 0 = **1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Everytime the Loss Function value should be near to 0, which our Neural Network is working good and accurately predicting results.\n",
    "\n",
    "To make the value of Loss function reach towards 0, we need to employ BACK PROPOGATION technique where we will use different optimizers, which will update the weights while going backwards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propogation\n",
    "\n",
    "Back Propogation is a process where in which its the opposite of the Forward Propogation. Here, we will use the help of Optimizers which updates the weights while we go backwards in the Neural network. \n",
    "\n",
    "This to and fro process combining both Forward and Backward propogation helps us to decrease the value of Loss function making it to reach near 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Neural Network\n",
    "\n",
    "Neural Network is like mimicking the whole brain using the concept of Neurons. Just like how we train a baby in the same way, we will train the Neural networks from scratch by using the help of weights and activation functions. \n",
    "\n",
    "For example, one day if some one shows a flower and says it is a Black Rose, and on the 2nd day we may not recollect but if we were told again like its a Black flower then the 3rd day our brain will automatically tell its name. \n",
    "\n",
    "In the similar fashion, we will use Forward and backward propogation to train our Neural Network efficiently. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
