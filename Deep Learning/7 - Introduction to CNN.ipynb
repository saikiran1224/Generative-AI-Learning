{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks\n",
    "\n",
    "Before understanding about CNN, lets understand how exactly it imitates the Human Brain and details of Image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN vs Human Brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Human Brain, we have the Cerebral Cortex, inside we have the Visual Cortex which helps us to visualize the images.\n",
    "\n",
    "Consider a person sees a Cat, Dog, and a Human in a Car. Visual cortex consists of multiple layers, like V1, V2, V3, ... V6. Once a person, sees the image the following actions are performed in each layer: \n",
    "- V1 - Observes the moving object\n",
    "- V2 - It first observes the animal(s) inside\n",
    "\n",
    "- V3 - Maps the environment\n",
    "- V4, V5 - Multiple tasks will be performed in each layer and layer by layer more information gets extracted\n",
    "- V6 - Final output will be shown (like its a Dog.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and its types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are measured by pixels. For example, if there is an image of 6 * 6, it means the image contains 6 rows * 6 columns. Each pixel inside the image will have a value ranging from 0 - 255. \n",
    "\n",
    "0 - Black color and 255 - White color\n",
    "\n",
    "Basically we have two types of Images,\n",
    "1. Black and White - single channel\n",
    "\n",
    "2. RGB (Red Green Blue) - three channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black and White image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Black and white image, there is only one channel. Either the pixel contains the value of 0 - Black or 255 - White. Hence, it is termed as Single channel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB Images are the images which are created by all the cameras currently in the world. Any color can be formed using the colors in RGB. Each channel named Red, Green and Blue have the values ranging from 0 - 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main and first layer in the Convolution Neural Network. In one convolution, there are many subprocesses involved. \n",
    "\n",
    "Lets us learn step-by-step process in detail. First let us assume there is an input image of size 6 x 6 pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Max Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So obviously inside the image the pixel values may range from 0 to 255. Before proceeding further, we need to normalize to them that means all the values should lie between 0 and 1. \n",
    "\n",
    "Hence, all the pixel values will be converted to either 0 or 1. This process is called as **Max Scaling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Applying the filter/kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply the filter for the input image, which helps us to extract information from the given image. This is called as Filter or Kernel. \n",
    "\n",
    "Filter has less dimensions compared to the input image. Once the filter is applied, then a grid of the same filter size gets considered in the input image, and then multiplied together and sum up which produces an output pixel value which will be obviously of lesser dimension. \n",
    "\n",
    "#### Stride\n",
    "\n",
    "Its defined as the next step. It is defined as the steps made by the grid in the input image. We will understand more about it in the coming example. \n",
    "\n",
    "E.g., Consider the input image is of 6x6 dimensions, and the filter/kernel applied is of 3x3 dimension. Now, our task is to compute matrix multiplication of 3x3 filter values with a 3x3 grid considered inside the input image. \n",
    "\n",
    "The sum of the value gets plotted in the output image of dimension 4x4. Similarly, the grid inside the input image gets changed continously until all the values gets completed. The change/shift of the grid is defined by the value of stride (steps it needs to move right or down) and the final values gets updated in the 4x4 image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two types of filters. They are: \n",
    "\n",
    "**1. Horizontal Edge filter:** This filter on applications helps us to detect the horizontal edges in the given image.\n",
    "\n",
    "**2. Vertical Edge filter:** This filter on applications helps us to detect the vertical edges in the given image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for calculation of output image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the image size is n, and the filter size is f, and stride size is s, then the output image size is given by the below formula: \n",
    "\n",
    "$\\displaystyle Output Dimension = \\frac {n - f + 1}{s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above step, when we have passed an image of 6x6 dimensions, we received an image of 4x4. It shows that there is a loss in the image since we are losing the dimensions and resulting in decreasing the quality or resolution of the image. \n",
    "\n",
    "To prevent this, we need to add Padding. Padding is defined as adding an additional compound over the Input image, which protects the original image with the help of a layer on top of it. Inshort, **Padding is added to prevent the loss of information in the image. There are various techniques which can be used.**\n",
    "\n",
    "E.g., Let us re-consider the previous example once again, in our case the input image is 6x6 now using padding we will add an layer on top of it, making the dimension increase to 8x8. \n",
    "\n",
    "The nearby pixel values will be auto-filled in the additional layer added. \n",
    "\n",
    "Now, lets calculate the output dimension of the image, using the values n = 8, f = 3, s = 1 then\n",
    "\n",
    "Output dimension = 8 - 3 + 1 / 1 = **6**. (Zero loss in the image).\n",
    "\n",
    "If we add the padding parameter in the formula, then it gets updated to as below: \n",
    "\n",
    "$\\displaystyle Output Dimension = \\frac {n + 2p - f + 1}{s}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the ANN, during the forward propogation we have used the Activation function in the hidden neuron, and the weights of the neurons are updated while traversing in the backward propogation. \n",
    "\n",
    "In CNN, the ReLU Activation function is used on the output image (will be applied on each and every value in the pixel which helps us to find the derivative that helps in further operations), and the filters/kernels are updated accordingly as per the input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is one Convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of all the above steps performed sequentially is termed as one Convolution. In one convolution, the following operations are performed:\n",
    "\n",
    "- Input image is passed, max scaling or normalization is performed\n",
    "\n",
    "- Padding is added to avoid losing information.\n",
    "- Filters are applied on the input image to extract information\n",
    "- Output image gets generated\n",
    "- ReLU activation function gets applied on the O/P image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is another layer applied post generation of output. This layer extracts the most important information identified by the filter. It helps to solve the problem of location invariance. After using multiple filters, we will able to extract more and more information from the image.\n",
    "\n",
    "To simplify, if filter 1 is able to extract some information, and filter 2 is able to extract some other information where filter 1 failed to do so. The Max pooling layer identifies and collates the most imporant information identified by both the filters. We will understand more about it with the help of example. \n",
    "\n",
    "There are total three types of pooling: \n",
    "1. Max pooling\n",
    "\n",
    "2. Min pooling\n",
    "3. Average pooling\n",
    "\n",
    "The type of pooling which needs to used gets decided as per the requirement of the problem statement. Convolutions and Max pooling are stacked together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 6x6 image containing picture of three cats. After adding padding, we received an output of 6x6 dimension. Here, for the first convolution we applied only one filter and the output image gets generated based on the data identified by the filter. Here the filter we applied is able to identify only one cat.\n",
    "\n",
    "Max pooling is applied on the output layer generated in the convolution. Similar to the working of filter, if our max pooling is 2x2 grid then a 2x2 grid gets considered on the Output layer where the Maximum value inside the 2x2 grid is taken and placed in the 2x2 max pooling grid. In the same way, the grid gets changed and the max pooling grid gets filled completely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer looks similar to the Artificial Neural Network (ANN) Dense layer. Once we get all the Max pooling 2x2 dimension images, we will flatten them into a single column which will determine our input neurons or nodes. \n",
    "\n",
    "Based on the output classess, expected we will have that many number of output classes. For example, we are building an Image classification model then as per the output classes we will have that many number of nodes in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Representation of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Convolution (filter + padding + stride) --> Max pooling layer --> Flattening layer --> ANN --> Final Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN Example](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*ERM2KbxLtbBg-1dpkJj5Bw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Credits: https://medium.com/@kritiikaaa/convolution-neural-networks-guide-for-your-first-cnn-project-7ea56f7f6960"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
